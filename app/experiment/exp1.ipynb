{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a CURRENCY: '5' in 'I have 5 apples and 3/4 of a pie.'\n",
      "Found a CURRENCY: '3/4' in 'I have 5 apples and 3/4 of a pie.'\n",
      "Found a CURRENCY: '1000' in 'The price is $1000.'\n",
      "Found a CURRENCY: '99.9' in 'He scored 99.9% on the test.'\n",
      "Found a CURRENCY: '3.14' in 'Pi is approximately 3.14.'\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# Load the SpaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Initialize the matcher with the shared vocab\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Define patterns\n",
    "# Pattern for integers and decimals\n",
    "# pattern_integers_decimals = [\n",
    "#     {\"IS_DIGIT\": True, \"OP\":\"?\"},  # integers (e.g., 5, 1000)\n",
    "#     {\"TEXT\": {\"REGEX\": r\"^\\d+\\.\\d+$\"}}  # decimals (e.g., 3.14, 2.5)\n",
    "# ]\n",
    "\n",
    "# # Pattern for percentages\n",
    "# pattern_percentages = [\n",
    "#     {\"TEXT\": {\"REGEX\": r\"^\\d+(\\.\\d+)?%$\"}, \"OP\":\"?\"}  # percentages (e.g., 25%, 99.9%)\n",
    "# ]\n",
    "\n",
    "\n",
    "# Pattern for currency values\n",
    "pattern_currency = [\n",
    "    {\"TEXT\": {\"REGEX\": r\"\\d\"}, \"OP\":\"?\"}  # currency (e.g., $1000, €50)\n",
    "]\n",
    "\n",
    "# Pattern for fractions\n",
    "# pattern_fractions = [\n",
    "#     {\"TEXT\": {\"REGEX\": r\"^\\d+\\/\\d+$\"},\"OP\":\"?\"}  # fractions (e.g., 3/4, 1/2)\n",
    "# ]\n",
    "\n",
    "# Add patterns to the matcher\n",
    "#matcher.add(\"INTEGER_DECIMAL\", [pattern_integers_decimals])\n",
    "# matcher.add(\"PERCENTAGE\", [pattern_percentages])\n",
    "pattern_currency = [\n",
    "    {\"TEXT\": {\"REGEX\": r\"\\d\"}, \"OP\":\"?\"}  # currency (e.g., $1000, €50)\n",
    "]\n",
    "matcher.add(\"CURRENCY\", [pattern_currency])\n",
    "\n",
    "sentences = [\n",
    "    \"I have 5 apples and 3/4 of a pie.\",\n",
    "    \"The price is $1000.\",\n",
    "    \"He scored 99.9% on the test.\",\n",
    "    \"Pi is approximately 3.14.\"\n",
    "]\n",
    "\n",
    "# Process each sentence with SpaCy\n",
    "for sentence in sentences:\n",
    "    doc = nlp(sentence)\n",
    "    matches = matcher(doc)\n",
    "    for match_id, start, end in matches:\n",
    "        span = doc[start:end]\n",
    "        match_type = nlp.vocab.strings[match_id]\n",
    "        print(f\"Found a {match_type}: '{span.text}' in '{sentence}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3/4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "span.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.18.0.post0-py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: nltk>=3.8 in c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages (from nltk>=3.8->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages (from nltk>=3.8->textblob) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages (from nltk>=3.8->textblob) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages (from nltk>=3.8->textblob) (4.11.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages (from click->nltk>=3.8->textblob) (0.4.6)\n",
      "Downloading textblob-0.18.0.post0-py3-none-any.whl (626 kB)\n",
      "   ---------------------------------------- 0.0/626.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/626.3 kB ? eta -:--:--\n",
      "    --------------------------------------- 10.2/626.3 kB ? eta -:--:--\n",
      "   - ------------------------------------- 30.7/626.3 kB 325.1 kB/s eta 0:00:02\n",
      "   -- ------------------------------------ 41.0/626.3 kB 326.8 kB/s eta 0:00:02\n",
      "   ---- ---------------------------------- 71.7/626.3 kB 357.2 kB/s eta 0:00:02\n",
      "   ------ ------------------------------- 112.6/626.3 kB 504.4 kB/s eta 0:00:02\n",
      "   ------- ------------------------------ 122.9/626.3 kB 479.3 kB/s eta 0:00:02\n",
      "   --------- ---------------------------- 163.8/626.3 kB 544.7 kB/s eta 0:00:01\n",
      "   ------------ ------------------------- 204.8/626.3 kB 565.6 kB/s eta 0:00:01\n",
      "   ------------ ------------------------- 204.8/626.3 kB 565.6 kB/s eta 0:00:01\n",
      "   ---------------- --------------------- 276.5/626.3 kB 607.9 kB/s eta 0:00:01\n",
      "   -------------------- ----------------- 337.9/626.3 kB 675.6 kB/s eta 0:00:01\n",
      "   ------------------------ ------------- 409.6/626.3 kB 750.7 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 491.5/626.3 kB 832.7 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 573.4/626.3 kB 901.1 kB/s eta 0:00:01\n",
      "   -------------------------------------- 626.3/626.3 kB 916.8 kB/s eta 0:00:00\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.18.0.post0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages\\mcqgenerator-0.0.1-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\n"
     ]
    }
   ],
   "source": [
    "!pip install -U textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\thean\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\brown.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\thean\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\thean\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\thean\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     C:\\Users\\thean\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\conll2000.zip.\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\thean\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\movie_reviews.zip.\n"
     ]
    }
   ],
   "source": [
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "text = \"a\"\n",
    "blob = TextBlob(text)\n",
    "sentiment = blob.sentiment\n",
    "\n",
    "# print(sentiment)  # Example output: Sentiment(polarity=0.6, subjectivity=0.9)\n",
    "\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "# sentiment_analyzer = nlp.create_pipe(\"sentiment_analyzer\")\n",
    "\n",
    "# nlp.add_pipe(sentiment_analyzer) \n",
    "# text = \"I love this product! It is the best thing I have ever bought.\"\n",
    "\n",
    "# sentiment = sentiment_analyzer(text)\n",
    "\n",
    "# print(sentiment.score) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misspelled Words: ['speling', 'sentense']\n",
      "No grammatical issues found.\n",
      "I (PRON, nsubj) -> speling\n",
      "speling (VERB, ROOT) -> speling\n",
      "mistake (NOUN, dobj) -> speling\n",
      "in (ADP, prep) -> speling\n",
      "this (DET, det) -> sentense\n",
      "sentense (NOUN, pobj) -> in\n",
      ". (PUNCT, punct) -> speling\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Initialize the spell checker\n",
    "spell = SpellChecker()\n",
    "\n",
    "def check_lexical_correctness(doc):\n",
    "    misspelled_words = []\n",
    "    for token in doc:\n",
    "        if not token.is_stop and not token.is_punct:\n",
    "            if token.text.lower() not in spell:\n",
    "                misspelled_words.append(token.text)\n",
    "    \n",
    "    return misspelled_words\n",
    "\n",
    "def check_grammatical_correctness(doc):\n",
    "    grammatical_issues = []\n",
    "    \n",
    "    # Check POS tags\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"X\":  # \"X\" is for other, unknown, or non-linguistic parts\n",
    "            grammatical_issues.append(f\"Unexpected POS tag '{token.pos_}' in word '{token.text}'\")\n",
    "    \n",
    "    # Check Dependency Parsing\n",
    "    for token in doc:\n",
    "        if token.dep_ == \"dep\":  # \"dep\" is a generic dependency label for unclassified relations\n",
    "            grammatical_issues.append(f\"Unclassified dependency in word '{token.text}'\")\n",
    "    \n",
    "    return grammatical_issues\n",
    "\n",
    "def analyze_text(text):\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Lexical Correctness\n",
    "    misspelled_words = check_lexical_correctness(doc)\n",
    "    if misspelled_words:\n",
    "        print(f\"Misspelled Words: {misspelled_words}\")\n",
    "    else:\n",
    "        print(\"No spelling mistakes found.\")\n",
    "    \n",
    "    # Grammatical Correctness\n",
    "    grammatical_issues = check_grammatical_correctness(doc)\n",
    "    if grammatical_issues:\n",
    "        print(f\"Grammatical Issues: {grammatical_issues}\")\n",
    "    else:\n",
    "        print(\"No grammatical issues found.\")\n",
    "    \n",
    "    # Display POS tags and Dependency Parsing\n",
    "    for token in doc:\n",
    "        print(f\"{token.text} ({token.pos_}, {token.dep_}) -> {token.head.text}\")\n",
    "    \n",
    "# Example usage\n",
    "text = \"I speling mistake in this sentense.\"\n",
    "analyze_text(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages (3.7.5)\n",
      "Collecting pyspellchecker\n",
      "  Downloading pyspellchecker-0.8.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages (from spacy) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages (from spacy) (0.12.5)\n",
      "Collecting tqdm<5.0.0,>=4.38.0 (from spacy)\n",
      "  Using cached tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages (from spacy) (2.7.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages (from spacy) (3.1.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages (from spacy) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages (from spacy) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy)\n",
      "  Using cached typer-0.9.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (6.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages (from jinja2->spacy) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Downloading pyspellchecker-0.8.1-py3-none-any.whl (6.8 MB)\n",
      "   ---------------------------------------- 0.0/6.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/6.8 MB 660.6 kB/s eta 0:00:11\n",
      "   ---------------------------------------- 0.1/6.8 MB 919.0 kB/s eta 0:00:08\n",
      "    --------------------------------------- 0.2/6.8 MB 1.2 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.2/6.8 MB 1.4 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.3/6.8 MB 1.5 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.4/6.8 MB 1.4 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.5/6.8 MB 1.4 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 0.5/6.8 MB 1.5 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 0.6/6.8 MB 1.5 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 0.7/6.8 MB 1.5 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 0.7/6.8 MB 1.5 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 0.8/6.8 MB 1.5 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 0.9/6.8 MB 1.5 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.0/6.8 MB 1.5 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.0/6.8 MB 1.5 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.1/6.8 MB 1.6 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 1.2/6.8 MB 1.5 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 1.3/6.8 MB 1.5 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 1.3/6.8 MB 1.5 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 1.4/6.8 MB 1.6 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 1.5/6.8 MB 1.6 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 1.6/6.8 MB 1.6 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 1.6/6.8 MB 1.6 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 1.7/6.8 MB 1.6 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 1.8/6.8 MB 1.6 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 1.9/6.8 MB 1.6 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 1.9/6.8 MB 1.6 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 2.0/6.8 MB 1.6 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 2.1/6.8 MB 1.6 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 2.1/6.8 MB 1.5 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 2.2/6.8 MB 1.6 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 2.3/6.8 MB 1.6 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 2.4/6.8 MB 1.6 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 2.5/6.8 MB 1.6 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 2.5/6.8 MB 1.6 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 2.6/6.8 MB 1.6 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 2.7/6.8 MB 1.6 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 2.7/6.8 MB 1.6 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 2.8/6.8 MB 1.6 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 2.9/6.8 MB 1.6 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 3.0/6.8 MB 1.6 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 3.0/6.8 MB 1.6 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 3.1/6.8 MB 1.6 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 3.2/6.8 MB 1.6 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 3.3/6.8 MB 1.6 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 3.3/6.8 MB 1.6 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 3.4/6.8 MB 1.6 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 3.5/6.8 MB 1.6 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 3.6/6.8 MB 1.6 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 3.7/6.8 MB 1.6 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 3.7/6.8 MB 1.6 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 3.8/6.8 MB 1.6 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 3.9/6.8 MB 1.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 4.0/6.8 MB 1.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 4.0/6.8 MB 1.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 4.1/6.8 MB 1.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 4.2/6.8 MB 1.6 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 4.3/6.8 MB 1.6 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 4.4/6.8 MB 1.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 4.4/6.8 MB 1.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 4.5/6.8 MB 1.6 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 4.6/6.8 MB 1.6 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 4.7/6.8 MB 1.6 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 4.7/6.8 MB 1.6 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 4.8/6.8 MB 1.6 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 4.9/6.8 MB 1.6 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 5.0/6.8 MB 1.6 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 5.0/6.8 MB 1.6 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 5.1/6.8 MB 1.6 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 5.2/6.8 MB 1.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 5.3/6.8 MB 1.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 5.4/6.8 MB 1.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 5.4/6.8 MB 1.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 5.5/6.8 MB 1.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 5.6/6.8 MB 1.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.7/6.8 MB 1.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.7/6.8 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 5.8/6.8 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 5.9/6.8 MB 1.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 6.0/6.8 MB 1.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 6.0/6.8 MB 1.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 6.1/6.8 MB 1.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 6.2/6.8 MB 1.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 6.3/6.8 MB 1.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 6.3/6.8 MB 1.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 6.4/6.8 MB 1.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.5/6.8 MB 1.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.6/6.8 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.7/6.8 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.8/6.8 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.8/6.8 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.8/6.8 MB 1.6 MB/s eta 0:00:00\n",
      "Using cached tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "Using cached typer-0.9.4-py3-none-any.whl (45 kB)\n",
      "Installing collected packages: tqdm, pyspellchecker, typer\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.11.2\n",
      "    Uninstalling tqdm-4.11.2:\n",
      "      Successfully uninstalled tqdm-4.11.2\n",
      "  Attempting uninstall: typer\n",
      "    Found existing installation: typer 0.12.5\n",
      "    Uninstalling typer-0.12.5:\n",
      "      Successfully uninstalled typer-0.12.5\n",
      "Successfully installed pyspellchecker-0.8.1 tqdm-4.66.5 typer-0.9.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\users\\thean\\anaconda3\\envs\\nlp\\lib\\site-packages\\mcqgenerator-0.0.1-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mcqgenerator 0.0.1 requires huggingfacehub, which is not installed.\n",
      "datasets 2.18.0 requires pyarrow>=12.0.0, but you have pyarrow 11.0.0 which is incompatible.\n",
      "fastapi-cli 0.0.4 requires typer>=0.12.3, but you have typer 0.9.4 which is incompatible.\n",
      "llama-index-embeddings-gemini 0.1.8 requires google-generativeai<0.6.0,>=0.5.2, but you have google-generativeai 0.7.2 which is incompatible.\n",
      "llama-index-llms-gemini 0.1.11 requires google-generativeai<0.6.0,>=0.5.2, but you have google-generativeai 0.7.2 which is incompatible.\n",
      "pyannote-audio 3.2.0 requires omegaconf<3.0,>=2.1, but you have omegaconf 1.4.1 which is incompatible.\n",
      "pyannote-database 5.1.0 requires typer>=0.12.1, but you have typer 0.9.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy pyspellchecker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
